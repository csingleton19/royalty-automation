from flask import Blueprint, jsonify, request
from services.data_extraction.pdf_extractor import extract_pdf_content
from services.data_extraction.data_cleaner import clean_extracted_text
from services.information_extraction.extractor import (
    extract_structured_data_with_llm,
    extract_unstructured_data_with_llm,
    extract_and_save_authors_data,
    save_data_as_json,
)
from config.config import BASE_DIR
import os
import pickle

# Create a Blueprint instance
extraction_api_blueprint = Blueprint("extraction_api", __name__)

# Load cleaned data from centralized storage
def load_cleaned_data():
    pickle_path = os.path.join(BASE_DIR, "storage/pickles", "cleaned_data.pkl")
    try:
        with open(pickle_path, "rb") as file:
            cleaned_data = pickle.load(file)
        return cleaned_data
    except FileNotFoundError:
        return None

@extraction_api.route("/extract-pdf", methods=["POST"])
def extract_pdf():
    if "file" not in request.files:
        return jsonify({"error": "No file provided"}), 400

    file = request.files["file"]
    if not file.filename.endswith(".pdf"):
        return jsonify({"error": "Only PDF files are supported"}), 400

    pdf_storage_path = os.path.join(BASE_DIR, "storage/pdfs", file.filename)
    file.save(pdf_storage_path)

    try:
        extracted_text = extract_pdf_content(pdf_storage_path)
        return jsonify({"status": "success", "extracted_text": extracted_text}), 200
    except Exception as e:
        return jsonify({"error": f"Failed to extract PDF content: {str(e)}"}), 500


@extraction_api.route("/clean-text", methods=["POST"])
def clean_text():
    data = request.get_json()
    if not data or "text" not in data:
        return jsonify({"error": "Text to clean not provided"}), 400

    raw_text = data["text"]
    cleaned_text = clean_extracted_text(raw_text)
    return jsonify({"status": "success", "cleaned_text": cleaned_text}), 200


@extraction_api.route("/extract-structured-data", methods=["POST"])
def extract_structured_data():
    data = load_cleaned_data()
    if data is None:
        return jsonify({"error": "Cleaned data not found"}), 404

    try:
        structured_data = extract_structured_data_with_llm(data)
        return jsonify({"status": "success", "structured_data": structured_data}), 200
    except Exception as e:
        return jsonify({"error": f"Failed to extract structured data: {str(e)}"}), 500


@extraction_api.route("/extract-unstructured-data", methods=["POST"])
def extract_unstructured_data():
    data = load_cleaned_data()
    if data is None:
        return jsonify({"error": "Cleaned data not found"}), 404

    try:
        unstructured_data = extract_unstructured_data_with_llm(data)
        return jsonify({"status": "success", "unstructured_data": unstructured_data}), 200
    except Exception as e:
        return jsonify({"error": f"Failed to extract unstructured data: {str(e)}"}), 500


@extraction_api.route("/save-authors-data", methods=["POST"])
def save_authors_data():
    data = load_cleaned_data()
    if data is None:
        return jsonify({"error": "Cleaned data not found"}), 404

    try:
        structured_data = extract_structured_data_with_llm(data)
        extract_and_save_authors_data(structured_data)
        return jsonify({"status": "success", "message": "Authors' data saved"}), 200
    except Exception as e:
        return jsonify({"error": f"Failed to save authors' data: {str(e)}"}), 500


@extraction_api.route("/save-unstructured-data", methods=["POST"])
def save_unstructured_data():
    data = load_cleaned_data()
    if data is None:
        return jsonify({"error": "Cleaned data not found"}), 404

    try:
        unstructured_data = extract_unstructured_data_with_llm(data)
        save_data_as_json(unstructured_data, "unstructured_data")
        return jsonify({"status": "success", "message": "Unstructured data saved"}), 200
    except Exception as e:
        return jsonify({"error": f"Failed to save unstructured data: {str(e)}"}), 500

